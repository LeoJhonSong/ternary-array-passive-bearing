{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "from torchkeras import KerasModel\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "from entity import *\n",
    "from utils import deg_pol2cart, analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "### 数据生成\n",
    "\n",
    "由于预测是实时的，因此GCC等计算不能在数据集中进行，应作为模型的一层。此处的数据就是原始信号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1500\n",
    "fs = 4 * 37500\n",
    "dist_max = 1\n",
    "n_max = int(np.ceil(dist_max / 1500 * fs))  # 采样频率下最大时延采样点数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python ./sim_data_generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict = np.load('train_sim_data.npz')\n",
    "array_signal = dataDict['array_signal']\n",
    "labels = dataDict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 750000, 151), (151,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_signal.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行加窗互相关，每个样本由$(C, L)$形状转为$(C, L // W, 2\\tau +1)$。W暂时选择1s的采样点数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成的是3通道，5s的数据，从15度到165度，采样率37500x4，共5x151个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigArrDataSet(Dataset):\n",
    "    def __init__(self, data, labels, period, fs):\n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.seq_len = period * fs  # 1周期为一个样本\n",
    "        self.labels = labels / 90 - 1  # 归一化到（-1，1）\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"数据集样本数=N/fs/period*len(labels)\"\"\"\n",
    "        return int(self.data.shape[1] / self.seq_len * self.data.shape[2])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: 下一步是从三通道5s数据中随机左右偏置，每个点位生成10个样本\n",
    "        div, res = divmod(idx, int(self.data.shape[1] / self.seq_len))\n",
    "        signals = self.data[:, res * self.seq_len:(res + 1) * self.seq_len, div]\n",
    "        return signals, self.labels[div]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(batch_size=10000):\n",
    "    # 同点位4个样本训练，一个用于评估，将数据集拆分为训练集和验证集\n",
    "    idx = 4 * 4 * 37500\n",
    "    # FIXME: 这个切片要改\n",
    "    train_data = array_signal[:, :idx, :]\n",
    "    val_data = array_signal[:, idx:, :]\n",
    "    ds_train = SigArrDataSet(train_data, labels, 1, 4 * 37500)\n",
    "    ds_val = SigArrDataSet(val_data, labels, 1, 4 * 37500)\n",
    "\n",
    "    # 目前样本很少，用很大的batch_size只分一批\n",
    "    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=False)\n",
    "    dl_val = DataLoader(ds_val, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=False)\n",
    "    return dl_train, dl_val\n",
    "\n",
    "dl_train, dl_val = create_dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义一维因果卷积层\n",
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1):\n",
    "        super().__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, padding=self.padding, dilation=dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv1d(x)[:, :, :x.size(2)]\n",
    "\n",
    "\n",
    "# 自定义一维因果CNN层\n",
    "# NOTE: 由于是CW信号，在有短脉冲的情况下归一化幅度会进一步压平相关峰，因此不使用GCC\n",
    "class CausalCnn1d(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        in_conv_channels = 1024\n",
    "        mid_conv_channels = 512\n",
    "        out_conv_channels = 128\n",
    "        kernel_size = 5\n",
    "        mid_depth = 4\n",
    "\n",
    "        self.in_layers = nn.Sequential(\n",
    "            CausalConv1d(in_channels, in_conv_channels, kernel_size),\n",
    "            nn.PReLU(in_conv_channels),\n",
    "        )\n",
    "\n",
    "        self.mid_layers = nn.ModuleList([\n",
    "            CausalConv1d(in_conv_channels, mid_conv_channels, kernel_size),\n",
    "            nn.PReLU(mid_conv_channels),\n",
    "        ])\n",
    "        self.mid_layers += nn.ModuleList([\n",
    "            CausalConv1d(mid_conv_channels, mid_conv_channels, kernel_size),\n",
    "            nn.PReLU(mid_conv_channels),\n",
    "        ] * (mid_depth - 1))\n",
    "\n",
    "        self.out_layers = nn.Sequential(\n",
    "            CausalConv1d(mid_conv_channels, out_conv_channels, kernel_size, dilation=2),\n",
    "            nn.PReLU(),\n",
    "            CausalConv1d(out_conv_channels, 1, kernel_size, dilation=2)  # 仅识别平面方位角，因此输出通道数为1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_layers(x)\n",
    "        for layer in self.mid_layers:\n",
    "            x = layer(x)\n",
    "        x = self.out_layers(x)\n",
    "        x = torch.tanh(x)  # 应当是用于将输出归一化到（-1，1）\n",
    "        return x\n",
    "\n",
    "class Xcorr(nn.Module):\n",
    "    def __init__(self, n_max):\n",
    "        super().__init__()\n",
    "        self.n_max = n_max\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"进行加窗互相关，窗口暂时设为整个序列长度，输入为（batch_size, channels, seq_len），输出为（batch_size, channels, 2*n_max+1）\n",
    "        \"\"\"\n",
    "        batch_size, channels, seq_len = x.size()\n",
    "        # conv1d本身不支持一批输入使用不同卷积内核，因此调整形状，将批量数调整到通道数维度，并行计算\n",
    "        y = x[:, [1, 2, 0], :].reshape((batch_size * channels, 1, seq_len))\n",
    "        x = x.reshape(1, batch_size * channels, seq_len)\n",
    "        # 以padding设置互相关计算的最大时延限制，减少计算量\n",
    "        return nn.functional.conv1d(x, y, groups=batch_size * channels, padding=self.n_max).reshape(batch_size, channels, -1)\n",
    "\n",
    "class CausalCnn1d_from_Xcorr(nn.Module):\n",
    "    def __init__(self, n_max, in_channels) -> None:\n",
    "        super().__init__()\n",
    "        self.xcorr = Xcorr(n_max)\n",
    "        self.cnn = CausalCnn1d(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.xcorr(x)\n",
    "        return self.cnn(x)\n",
    "\n",
    "\n",
    "net = CausalCnn1d_from_Xcorr(n_max, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b, c = np.array((1, 2, 3, 4, 6, 3)), np.array((1, 2, 3, 4, 6, 3)), np.array((1, 3, 5, 6, 3, 0))\n",
    "# print(np.correlate(a, b, mode='same'), np.correlate(b, c, mode='same'), np.correlate(c, a, mode='same'))\n",
    "# t = np.stack((np.stack((a, b, c), axis=0),\n",
    "#      np.stack((c, b, a), axis=0)), axis=0)\n",
    "# t = torch.from_numpy(t).float()\n",
    "# x = t.reshape(1, 6, -1)\n",
    "# y = t[:, [1, 2, 0], :].reshape((6, 1, -1))\n",
    "# print(nn.functional.conv1d(x, y, groups=6, padding='same').reshape(2, 3, -1))\n",
    "# model = Xcorr(2)\n",
    "# print(model(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasModel(\n",
    "    net,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    metrics_dict={'acc': Accuracy(task='multiclass', num_classes=151)},\n",
    "    optimizer=optim.Adam(net.parameters(), lr=1e-3)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    dl_train,\n",
    "    dl_val,\n",
    "    epochs=10,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, train_dataset, test_dataset, epochs, batch_size, device, lr, scheduler_kwargs):\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)  # 可学习参数, 学习率 (超参数)\n",
    "#     scheduler = optim.lr_scheduler.StepLR(optimizer, **scheduler_kwargs)  # 学习率调整\n",
    "\n",
    "#     model.train()\n",
    "#     model.to(device)\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         for data, target in train_dataset:\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(data)\n",
    "#             loss = criterion(output, target)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#         model.eval()\n",
    "#         test_loss = 0\n",
    "#         correct = 0\n",
    "#         with torch.no_grad():\n",
    "#             for data, target in test_dataset:\n",
    "#                 output = model(data)\n",
    "#                 test_loss += criterion(output, target).item()\n",
    "#                 pred = output.argmax(dim=1, keepdim=True)\n",
    "#                 correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#         test_loss /= len(test_dataset.dataset)\n",
    "#         # print(f\"Epoch {epoch}: Test set: Average loss: {test_loss}, Accuracy: {correct}/{len(test_dataset.dataset)} ({100. * correct / len(test_dataset.dataset)}%)\")\n",
    "#         scheduler.step() # 更新学习率\n",
    "#     print('训练结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "\n",
    "# EPOCHS = 30\n",
    "# BATCH_SIZE = 32\n",
    "# LR = 1e-3\n",
    "# print(device := torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Cnn_from_GCC()\n",
    "\n",
    "# train(\n",
    "#     model=model,\n",
    "#     train_dataset=train_dataset,\n",
    "#     test_dataset=test_dataset,\n",
    "#     epochs=EPOCHS,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     device=device,\n",
    "#     lr=LR,\n",
    "#     scheduler_kwargs={'step_size': 10, 'gamma': 0.1},  # 每10个epoch学习率乘0.1, 避免后期学习率过大导致损失震荡\n",
    "# )\n",
    "\n",
    "# torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect():\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Cnn_from_GCC()\n",
    "# model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
